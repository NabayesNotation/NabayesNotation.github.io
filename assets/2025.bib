@article{Kirsch2019,
	abstract = {A sequence of random variables is called exchangeable if the joint distribution of the sequence is unchanged by any permutation of the indices. De Finetti's theorem characterizes all {0,1}-valued exchangeable sequences as a `mixture' of sequences of independent random variables. We present a new, elementary proof of de Finetti's Theorem. The purpose of this paper is to make this theorem accessible to a broader community through an essentially self-contained proof.},
	author = {Werner Kirsch},
	doi = {https://doi.org/10.1016/j.spl.2019.03.014},
	issn = {0167-7152},
	journal = {Statistics \& Probability Letters},
	keywords = {Exchangeable random variables, de Finetti's Theorem, Moment method},
	pages = {84-88},
	title = {An elementary proof of de Finetti's theorem},
	url = {https://www.sciencedirect.com/science/article/pii/S0167715219300902},
	volume = {151},
	year = {2019},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0167715219300902},
	bdsk-url-2 = {https://doi.org/10.1016/j.spl.2019.03.014}}
@book{Castillo2024,
  author = {Ismaël Castillo},
  year = {2024},
  title = {Bayesian Nonparametric Statistics},
  series = {École d’Été de Probabilités de Saint-Flour LI - 2023},
  volume = {},
  edition = {},
  url = {https://doi.org/10.1007/978-3-031-74035-0},
  publisher = {Springer Cham}
}
@article{Ferguson1973,
 ISSN = {00905364},
 URL = {http://www.jstor.org/stable/2958008},
 author = {Thomas S. Ferguson},
 journal = {The Annals of Statistics},
 number = {2},
 pages = {209--230},
 publisher = {Institute of Mathematical Statistics},
 title = {A Bayesian Analysis of Some Nonparametric Problems},
 urldate = {2024-07-01},
 volume = {1},
 year = {1973}
}
@article{Freedman1963,
author = {David A. Freedman},
title = {{On the Asymptotic Behavior of Bayes' Estimates in the Discrete Case}},
volume = {34},
journal = {The Annals of Mathematical Statistics},
number = {4},
publisher = {Institute of Mathematical Statistics},
pages = {1386 -- 1403},
year = {1963},
doi = {10.1214/aoms/1177703871},
URL = {https://doi.org/10.1214/aoms/1177703871}
}
@article{Fabius1964,
author = {J. Fabius},
title = {{Asymptotic Behavior of Bayes' Estimates}},
volume = {35},
journal = {The Annals of Mathematical Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {846 -- 856},
year = {1964},
doi = {10.1214/aoms/1177703584},
URL = {https://doi.org/10.1214/aoms/1177703584}
}
@article{Lavine1992,
author = {Michael Lavine},
title = {{Some Aspects of Polya Tree Distributions for Statistical Modelling}},
volume = {20},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1222 -- 1235},
keywords = {Dirichlet processes, nonparametric Bayes, tailfree processes},
year = {1992},
doi = {10.1214/aos/1176348767},
URL = {https://doi.org/10.1214/aos/1176348767}
}
@article{Mauldin+1992,
author = {R. Daniel Mauldin and William D. Sudderth and S. C. Williams},
title = {{Polya Trees and Random Distributions}},
volume = {20},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1203 -- 1221},
keywords = {Derechlet distributions, Polya urns, Prior distributions, Random measures},
year = {1992},
doi = {10.1214/aos/1176348766},
URL = {https://doi.org/10.1214/aos/1176348766}
}
@article{Castillo2017,
author = {Isma{\"e}l Castillo},
title = {{Pólya tree posterior distributions on densities}},
volume = {53},
journal = {Annales de l'Institut Henri Poincaré, Probabilités et Statistiques},
number = {4},
publisher = {Institut Henri Poincaré},
pages = {2074 -- 2102},
keywords = {Bayesian Donsker theorem, Bayesian nonparametrics, Bernstein–von Mises theorem, Minimax rate, Pólya tree distribution, Supremum norm convergence},
year = {2017},
doi = {10.1214/16-AIHP784},
URL = {https://doi.org/10.1214/16-AIHP784}
}
@article{荒木信一2019,
  title={III．DKD重症化予防のための集学的治療},
  author={荒木信一},
  journal={日本内科学会雑誌},
  volume={108},
  number={5},
  pages={916-922},
  year={2019},
  doi={10.2169/naika.108.916}
}

@article{Araki2018,
	abstract = {Diabetic kidney disease (DKD) in patients with type 2 diabetes mellitus is a leading cause of end-stage renal disease worldwide. An increase in the severity of albuminuria and a decrease in the glomerular filtration rate, by which the DKD stages are categorized, are associated with higher risks of not only end-stage renal disease but also all-cause mortality and cardiovascular mortality. Thus, an optimal management strategy and adequate assessment of therapeutic success are of great clinical and societal relevance to improve the prognosis in patients with type 2 diabetes mellitus and DKD. At present, comprehensive risk management for glycemia, blood pressure, lipid profile, and lifestyle habits is emphasized with respect to cardio-renal protection, rather than one single risk management approach. However, the pharmacological therapy aiming at strict control of these risk factors may be associated with an increased risk of adverse effects, particularly in older adults with diabetes. Accordingly, in the clinical practice of diabetes care, we need to individualize the treatment goals for each risk factor according to the health and social status of each patient with type 2 diabetes mellitus and DKD.},
	author = {Araki, Shin-ichi},
	date = {2018/05/01},
	date-added = {2024-12-25 21:04:15 +0900},
	date-modified = {2024-12-25 21:04:15 +0900},
	doi = {10.1007/s13340-018-0351-5},
	id = {Araki2018},
	isbn = {2190-1686},
	journal = {Diabetology International},
	number = {2},
	pages = {100--107},
	title = {Comprehensive risk management of diabetic kidney disease in patients with type 2 diabetes mellitus},
	url = {https://doi.org/10.1007/s13340-018-0351-5},
	volume = {9},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1007/s13340-018-0351-5}}

@article{Oellgaard+2017,
	annote = {doi: 10.1016/j.kint.2016.11.023},
	author = {Oellgaard, Jens and G{\ae}de, Peter and Rossing, Peter and Persson, Frederik and Parving, Hans-Henrik and Pedersen, Oluf},
	date = {2017/04/01},
	date-added = {2024-12-25 21:13:07 +0900},
	date-modified = {2024-12-25 21:13:07 +0900},
	doi = {10.1016/j.kint.2016.11.023},
	isbn = {0085-2538},
	journal = {Kidney International},
	journal1 = {Kidney International},
	month = {2024/12/25},
	number = {4},
	pages = {982--988},
	publisher = {Elsevier},
	title = {Intensified multifactorial intervention in type 2 diabetics with microalbuminuria leads to long-term renal benefits},
	type = {doi: 10.1016/j.kint.2016.11.023},
	url = {https://doi.org/10.1016/j.kint.2016.11.023},
	volume = {91},
	year = {2017},
	year1 = {2017},
	bdsk-url-1 = {https://doi.org/10.1016/j.kint.2016.11.023}}

@InProceedings{Lopez-Paz+2013,
  title = 	 {Gaussian Process Vine Copulas for Multivariate Dependence},
  author = 	 {Lopez-Paz, David and Hernández-Lobato, Jose Miguel and Zoubin, Ghahramani},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {10--18},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  number =       {2},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/lopez-paz13.pdf},
  url = 	 {https://proceedings.mlr.press/v28/lopez-paz13.html},
  abstract = 	 {Copulas allow to learn marginal distributions separately from the multivariate dependence structure (copula) that links them together into a density function.  Vine factorizations ease the learning of high-dimensional copulas by constructing a hierarchy of conditional bivariate copulas. However, to simplify inference, it is common to assume that each of these conditional bivariate copulas is independent from its conditioning variables.  In this paper, we relax this assumption by discovering the latent functions that specify the shape of a conditional copula given its conditioning variables.  We learn these functions by following a Bayesian approach based on sparse Gaussian processes with expectation propagation for scalable, approximate inference. Experiments on real-world datasets show that, when modeling all conditional dependencies, we obtain better estimates of the underlying copula of the data.}
}
@article{Stephens2000,
author = {Matthew Stephens},
title = {{Bayesian analysis of mixture models with an unknown number of components—an alternative to reversible jump methods}},
volume = {28},
journal = {The Annals of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {40 -- 74},
keywords = {Bayesian analysis, birth-death process, Markov process, MCMC, mixture model, model choice, Reversible jump, spatial point process},
year = {2000},
doi = {10.1214/aos/1016120364},
URL = {https://doi.org/10.1214/aos/1016120364}
}
@article{Cappe+2003,
    author = {Cappé, Olivier and Robert, Christian P. and Rydén, Tobias},
    title = {Reversible Jump, Birth-and-Death and More General Continuous Time Markov Chain Monte Carlo Samplers},
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {65},
    number = {3},
    pages = {679-700},
    year = {2003},
    month = {07},
    abstract = { Reversible jump methods are the most commonly used Markov chain Monte Carlo tool for exploring variable dimension statistical models. Recently, however, an alternative approach based on birth-and-death processes has been proposed by Stephens for mixtures of distributions. We show that the birth-and-death setting can be generalized to include other types of continuous time jumps like split-and-combine moves in the spirit of Richardson and Green. We illustrate these extensions both for mixtures of distributions and for hidden Markov models. We demonstrate the strong similarity of reversible jump and continuous time methodologies by showing that, on appropriate rescaling of time, the reversible jump chain converges to a limiting continuous time birth-and-death process. A numerical comparison in the setting of mixtures of distributions highlights this similarity.},
    issn = {1369-7412},
    doi = {10.1111/1467-9868.00409},
    url = {https://doi.org/10.1111/1467-9868.00409},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/65/3/679/49795366/jrsssb\_65\_3\_679.pdf},
}
@article{Carlin-Polson1991,
 ISSN = {03195724},
 URL = {http://www.jstor.org/stable/3315430},
 abstract = {A Bayesian approach to modeling a rich class of nonconjugate problems is presented. An adaptive Monte Carlo integration technique known as the Gibbs sampler is proposed as a mechanism for implementing a conceptually and computationally simple solution in such a framework. The result is a general strategy for obtaining marginal posterior densities under changing specification of the model error densities and related prior densities. We illustrate the approach in a nonlinear regression setting, comparing the merits of three candidate error distributions. /// Une approche bayesienne est présentée afin d'aborder une classe étendue de problèmes du type non conjugué. Une technique adaptative d'intégration Monte Carlo, l'échantillonneur de Gibbs, est proposée; elle apporte une solution simple tant du point de vue conceptuel que du point de vue calculatoire. Le résultat procure une stratégie générale dans le but d'obtenir des densités a posteriori marginales lorsque les lois des erreurs, et les lois a priori correspondantes, sont altérées. L'approche est illustrée dans un contexte de régression non linéaire où les mérites de trois lois pour les erreurs sont comparés.},
 author = {Bradley P. Carlin and Nicholas G. Polson},
 journal = {The Canadian Journal of Statistics / La Revue Canadienne de Statistique},
 number = {4},
 pages = {399--405},
 publisher = {[Statistical Society of Canada, Wiley]},
 title = {Inference for Nonconjugate Bayesian Models Using the Gibbs Sampler},
 urldate = {2024-12-28},
 volume = {19},
 year = {1991}
}

@article{Chib1995,
	annote = {doi: 10.1080/01621459.1995.10476635},
	author = {Chib ,Siddhartha},
	date = {1995/12/01},
	date-added = {2024-12-28 21:25:00 +0900},
	date-modified = {2024-12-28 21:25:00 +0900},
	doi = {10.1080/01621459.1995.10476635},
	isbn = {0162-1459},
	journal = {Journal of the American Statistical Association},
	journal1 = {Journal of the American Statistical Association},
	journal2 = {Journal of the American Statistical Association},
	month = {12},
	number = {432},
	pages = {1313--1321},
	publisher = {ASA Website},
	title = {Marginal Likelihood from the Gibbs Output},
	type = {doi: 10.1080/01621459.1995.10476635},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1995.10476635},
	volume = {90},
	year = {1995},
	year1 = {1995},
	bdsk-url-1 = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1995.10476635},
	bdsk-url-2 = {https://doi.org/10.1080/01621459.1995.10476635}}

@article{Han-Carlin2001,
	annote = {doi: 10.1198/016214501753208780},
	author = {Han ,Cong and Carlin ,Bradley P},
	date = {2001/09/01},
	date-added = {2024-12-28 21:26:23 +0900},
	date-modified = {2024-12-28 21:26:23 +0900},
	doi = {10.1198/016214501753208780},
	isbn = {0162-1459},
	journal = {Journal of the American Statistical Association},
	journal1 = {Journal of the American Statistical Association},
	journal2 = {Journal of the American Statistical Association},
	month = {09},
	number = {455},
	pages = {1122--1132},
	publisher = {ASA Website},
	title = {Markov Chain Monte Carlo Methods for Computing Bayes Factors},
	type = {doi: 10.1198/016214501753208780},
	url = {https://doi.org/10.1198/016214501753208780},
	volume = {96},
	year = {2001},
	year1 = {2001},
	bdsk-url-1 = {https://doi.org/10.1198/016214501753208780}}
@article{Carlin-Chib1995,
    author = {Carlin, Bradley P. and Chib, Siddhartha},
    title = {Bayesian Model Choice Via Markov Chain Monte Carlo Methods},
    journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
    volume = {57},
    number = {3},
    pages = {473-484},
    year = {1995},
    month = {12},
    abstract = {Markov chain Monte Carlo (MCMC) integration methods enable the fitting of models of virtually unlimited complexity, and as such have revolutionized the practice of Bayesian data analysis. However, comparison across models may not proceed in a completely analogous fashion, owing to violations of the conditions sufficient to ensure convergence of the Markov chain. In this paper we present a framework for Bayesian model choice, along with an MCMC algorithm that does not suffer from convergence difficulties. Our algorithm applies equally well to problems where only one model is contemplated but its proper size is not known at the outset, such as problems involving integer-valued parameters, multiple changepoints or finite mixture distributions. We illustrate our approach with two published examples.},
    issn = {0035-9246},
    doi = {10.1111/j.2517-6161.1995.tb02042.x},
    url = {https://doi.org/10.1111/j.2517-6161.1995.tb02042.x},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/57/3/473/49100124/jrsssb\_57\_3\_473.pdf},
}



@article{Godsill2001,
	annote = {doi: 10.1198/10618600152627924},
	author = {Godsill ,Simon J},
	date = {2001/06/01},
	date-added = {2024-12-28 21:53:00 +0900},
	date-modified = {2024-12-28 21:53:00 +0900},
	doi = {10.1198/10618600152627924},
	isbn = {1061-8600},
	journal = {Journal of Computational and Graphical Statistics},
	journal1 = {Journal of Computational and Graphical Statistics},
	journal2 = {Journal of Computational and Graphical Statistics},
	month = {06},
	number = {2},
	pages = {230--248},
	publisher = {ASA Website},
	title = {On the Relationship Between Markov chain Monte Carlo Methods for Model Uncertainty},
	type = {doi: 10.1198/10618600152627924},
	url = {https://doi.org/10.1198/10618600152627924},
	volume = {10},
	year = {2001},
	year1 = {2001},
	bdsk-url-1 = {https://doi.org/10.1198/10618600152627924}}
@article{Hoeting+1999,
author = {Jennifer A. Hoeting and David Madigan and Adrian E. Raftery and Chris T. Volinsky},
title = {{Bayesian model averaging: a tutorial (with comments by M. Clyde, David Draper and E. I. George, and a rejoinder by the authors}},
volume = {14},
journal = {Statistical Science},
number = {4},
publisher = {Institute of Mathematical Statistics},
pages = {382 -- 417},
keywords = {Bayesian graphical models, Bayesian model averaging, learning, Markov chain Monte Carlo, model uncertainty},
year = {1999},
doi = {10.1214/ss/1009212519},
URL = {https://doi.org/10.1214/ss/1009212519}
}
@book{Hastie+2015,
  author = {Trevor Hastie and Robert Tibshirani and Martin Wainwright},
  year = {2015},
  title = {Statistical Learning with Sparsity: The Lasso and Generalizations},
  series = {},
  volume = {},
  edition = {},
  url = {https://doi.org/10.1201/b18401},
  publisher = {Chapman and Hall/CRC}
}
@article{George-McCulloch1997,
 ISSN = {10170405, 19968507},
 URL = {http://www.jstor.org/stable/24306083},
 abstract = {This paper describes and compares various hierarchical mixture prior formulations of variable selection uncertainty in normal linear regression models. These include the nonconjugate SSVS formulation of George and McCulloch (1993), as well as conjugate formulations which allow for analytical simplification. Hyperparameter settings which base selection on practical significance, and the implications of using mixtures with point priors are discussed. Computational methods for posterior evaluation and exploration are considered. Rapid updating methods are seen to provide feasible methods for exhaustive evaluation using Gray Code sequencing in moderately sized problems, and fast Markov Chain Monte Carlo exploration in large problems. Estimation of normalization constants is seen to provide improved posterior estimates of individual model probabilities and the total visited probability. Various procedures are illustrated on simulated sample problems and on a real problem concerning the construction of financial index tracking portfolios.},
 author = {Edward I. George and Robert E. McCulloch},
 journal = {Statistica Sinica},
 number = {2},
 pages = {339--373},
 publisher = {Institute of Statistical Science, Academia Sinica},
 title = {APPROACHES FOR BAYESIAN VARIABLE SELECTION},
 urldate = {2024-12-28},
 volume = {7},
 year = {1997}
}
@article{Bhadra+2019,
author = {Anindya Bhadra and Jyotishka Datta and Nicholas G. Polson and Brandon Willard},
title = {{Lasso Meets Horseshoe: A Survey}},
volume = {34},
journal = {Statistical Science},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {405 -- 427},
keywords = {Global-local priors, horseshoe, horseshoe+, hyper-parameter tuning, Lasso, regression, regularization, Sparsity},
year = {2019},
doi = {10.1214/19-STS700},
URL = {https://doi.org/10.1214/19-STS700}
}
@misc{Griffin2024,
      title={Expressing and visualizing model uncertainty in Bayesian variable selection using Cartesian credible sets}, 
      author={Jim E. Griffin},
      year={2024},
      eprint={2402.12323},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
      url={https://arxiv.org/abs/2402.12323}, 
}
@article{Porwal-Raftery2022,
author = {Anupreet Porwal  and Adrian E. Raftery},
title = {Comparing methods for statistical inference with model uncertainty},
journal = {Proceedings of the National Academy of Sciences},
volume = {119},
number = {16},
pages = {e2120737119},
year = {2022},
doi = {10.1073/pnas.2120737119},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2120737119},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2120737119},
abstract = {Choosing a statistical model and accounting for uncertainty about this choice are important parts of the scientific process and are required for common statistical tasks such as parameter estimation, interval estimation, statistical inference, point prediction, and interval prediction. A canonical example is the choice of variables in a linear regression model. Many ways of doing this have been proposed, including Bayesian and penalized regression methods, and it is not clear which are best. We compare 21 popular methods via an extensive simulation study based on a wide range of real datasets. We found that three adaptive Bayesian model averaging methods performed best across all the statistical tasks and that two of these were also among the most computationally efficient. Probability models are used for many statistical tasks, notably parameter estimation, interval estimation, inference about model parameters, point prediction, and interval prediction. Thus, choosing a statistical model and accounting for uncertainty about this choice are important parts of the scientific process. Here we focus on one such choice, that of variables to include in a linear regression model. Many methods have been proposed, including Bayesian and penalized likelihood methods, and it is unclear which one to use. We compared 21 of the most popular methods by carrying out an extensive set of simulation studies based closely on real datasets that span a range of situations encountered in practical data analysis. Three adaptive Bayesian model averaging (BMA) methods performed best across all statistical tasks. These used adaptive versions of Zellner’s g-prior for the parameters, where the prior variance parameter g is a function of sample size or is estimated from the data. We found that for BMA methods implemented with Markov chain Monte Carlo, 10,000 iterations were enough. Computationally, we found two of the three best methods (BMA with g=n and empirical Bayes-local) to be competitive with the least absolute shrinkage and selection operator (LASSO), which is often preferred as a variable selection technique because of its computational efficiency. BMA performed better than Bayesian model selection (in which just one model is selected).}}
@article{Castillo+2015,
author = {Isma{\"e}l Castillo and Johannes Schmidt-Hieber and Aad van der Vaart},
title = {{Bayesian linear regression with sparse priors}},
volume = {43},
journal = {The Annals of Statistics},
number = {5},
publisher = {Institute of Mathematical Statistics},
pages = {1986 -- 2018},
keywords = {Bayesian inference, Sparsity},
year = {2015},
doi = {10.1214/15-AOS1334},
URL = {https://doi.org/10.1214/15-AOS1334}
}
@article{West1987,
    author = {Mike West},
    title = {On scale mixtures of normal distributions},
    journal = {Biometrika},
    volume = {74},
    number = {3},
    pages = {646-648},
    year = {1987},
    month = {09},
    abstract = {The exponential power family of distributions of Box \&amp; Tiao (1973) is shown to be a subset of the class of scale mixtures of normals. The corresponding mixing distributions are explicitly obtained, identifying a close relationship between the exponential power family and a further class of normal scale mixtures, namely the stable distributions.},
    issn = {0006-3444},
    doi = {10.1093/biomet/74.3.646},
    url = {https://doi.org/10.1093/biomet/74.3.646},
    eprint = {https://academic.oup.com/biomet/article-pdf/74/3/646/656269/74-3-646.pdf},
}

@incollection{Polson-Scott2011,
    author = {Polson, Nicholas G. and Scott, James G.},
    isbn = {9780199694587},
    title = {501Shrink Globally, Act Locally: Sparse Bayesian Regularization and Prediction},
    booktitle = {Bayesian Statistics 9},
    publisher = {Oxford University Press},
    year = {2011},
    month = {10},
    abstract = {We study the classic problem of choosing a prior distribution for a location parameter β = (β  1,…, β  p) as p grows large. First, we study the standard “global‐local shrinkage” approach, based on scale mixtures of normals. Two theorems are presented which characterize certain desirable properties of shrinkage priors for sparse problems. Next, we review some recent results showing how Lévy processes can be used to generate infinite‐dimensional versions of standard normal scale‐mixture priors, along with new priors that have yet to be seriously studied in the literature. This approach provides an intuitive framework both for generating new regularization penalties and shrinkage rules, and for performing asymptotic analysis on existing models.},
    doi = {10.1093/acprof:oso/9780199694587.003.0017},
    url = {https://doi.org/10.1093/acprof:oso/9780199694587.003.0017},
    eprint = {https://academic.oup.com/book/0/chapter/141655378/chapter-ag-pdf/45229839/book\_1879\_section\_141655378.ag.pdf},
}

@article{Hans2011,
	annote = {doi: 10.1198/jasa.2011.tm09241},
	author = {Hans ,Chris},
	date = {2011/12/01},
	date-added = {2024-12-29 13:41:47 +0900},
	date-modified = {2024-12-29 13:41:47 +0900},
	doi = {10.1198/jasa.2011.tm09241},
	isbn = {0162-1459},
	journal = {Journal of the American Statistical Association},
	journal1 = {Journal of the American Statistical Association},
	journal2 = {Journal of the American Statistical Association},
	month = {12},
	number = {496},
	pages = {1383--1393},
	publisher = {ASA Website},
	title = {Elastic Net Regression Modeling With the Orthant Normal Prior},
	type = {doi: 10.1198/jasa.2011.tm09241},
	url = {https://doi.org/10.1198/jasa.2011.tm09241},
	volume = {106},
	year = {2011},
	year1 = {2011},
	bdsk-url-1 = {https://doi.org/10.1198/jasa.2011.tm09241}}
@article{Hans2009,
 ISSN = {00063444, 14643510},
 URL = {http://www.jstor.org/stable/27798870},
 abstract = {The lasso estimate for linear regression corresponds to a posterior mode when independent, double-exponential prior distributions are placed on the regression coefficients. This paper introduces new aspects of the broader Bayesian treatment of lasso regression. A direct characterization of the regression coefficients' posterior distribution is provided, and computation and inference under this characterization is shown to be straightforward. Emphasis is placed on point estimation using the posterior mean, which facilitates prediction of future observations via the posterior predictive distribution. It is shown that the standard lasso prediction method does not necessarily agree with model-based, Bayesian predictions. A new Gibbs sampler for Bayesian lasso regression is introduced.},
 author = {Chris Hans},
 journal = {Biometrika},
 number = {4},
 pages = {835--845},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {Bayesian lasso regression},
 urldate = {2024-12-28},
 volume = {96},
 year = {2009}
}
@article{Tibshirani1996,
    author = {Tibshirani, Robert},
    title = {Regression Shrinkage and Selection Via the Lasso},
    journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
    volume = {58},
    number = {1},
    pages = {267-288},
    year = {1996},
    month = {12},
    abstract = {We propose a new method for estimation in linear models. The ‘lasso’ minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
    issn = {0035-9246},
    doi = {10.1111/j.2517-6161.1996.tb02080.x},
    url = {https://doi.org/10.1111/j.2517-6161.1996.tb02080.x},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/58/1/267/49098631/jrsssb\_58\_1\_267.pdf},
}

@article{Ishwaran-Rao2005,
author = {Hemant Ishwaran and J. Sunil Rao},
title = {{Spike and slab variable selection: Frequentist and Bayesian strategies}},
volume = {33},
journal = {The Annals of Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {730 -- 773},
keywords = {Generalized ridge regression, hypervariance, model averaging, model uncertainty, ordinary least squares, Penalization, rescaling, shrinkage, stochastic variable selection, Zcut},
year = {2005},
doi = {10.1214/009053604000001147},
URL = {https://doi.org/10.1214/009053604000001147}
}
@article{Piironen+2020,
author = {Juho Piironen and Markus Paasiniemi and Aki Vehtari},
title = {{Projective inference in high-dimensional problems: Prediction and feature selection}},
volume = {14},
journal = {Electronic Journal of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics and Bernoulli Society},
pages = {2155 -- 2197},
keywords = {Feature selection, Post-selection inference, prediction, projection, Sparsity},
year = {2020},
doi = {10.1214/20-EJS1711},
URL = {https://doi.org/10.1214/20-EJS1711}
}
@article{Li-Dutta-Roy2023,
author = {Dongjin Li and Somak Dutta and Vivekananda Roy},
title = {Model Based Screening Embedded Bayesian Variable Selection for Ultra-high Dimensional Settings},
journal = {Journal of Computational and Graphical Statistics},
volume = {32},
number = {1},
pages = {61--73},
year = {2023},
publisher = {ASA Website},
doi = {10.1080/10618600.2022.2074428},
URL = {https://doi.org/10.1080/10618600.2022.2074428}}
@article{Smith-Gelfand1992,
 ISSN = {00031305},
 URL = {http://www.jstor.org/stable/2684170},
 abstract = {Even to the initiated, statistical calculations based on Bayes's Theorem can be daunting because of the numerical integrations required in all but the simplest applications. Moreover, from a teaching perspective, introductions to Bayesian statistics-if they are given at all-are circumscribed by these apparent calculational difficulties. Here we offer a straightforward sampling-resampling perspective on Bayesian inference, which has both pedagogic appeal and suggests easily implemented calculation strategies.},
 author = {A. F. M. Smith and A. E. Gelfand},
 journal = {The American Statistician},
 number = {2},
 pages = {84--88},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Bayesian Statistics without Tears: A Sampling-Resampling Perspective},
 urldate = {2024-12-29},
 volume = {46},
 year = {1992}
}
@book{Ripley1987,
  author = {Brian D. Ripley},
  year = {1987},
  title = {Stochastic Simulation},
  series = {Wiley Series in Probability and Statistics},
  volume = {},
  edition = {},
  doi = {10.1002/9780470316726},
  publisher = {John Wiley \& Sons}
}
@article{Zanella-Roberts2019,
    author = {Zanella, Giacomo and Roberts, Gareth},
    title = {Scalable Importance Tempering and Bayesian Variable Selection},
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {81},
    number = {3},
    pages = {489-517},
    year = {2019},
    month = {03},
    abstract = {We propose a Monte Carlo algorithm to sample from high dimensional probability distributions that combines Markov chain Monte Carlo and importance sampling. We provide a careful theoretical analysis, including guarantees on robustness to high dimensionality, explicit comparison with standard Markov chain Monte Carlo methods and illustrations of the potential improvements in efficiency. Simple and concrete intuition is provided for when the novel scheme is expected to outperform standard schemes. When applied to Bayesian variable-selection problems, the novel algorithm is orders of magnitude more efficient than available alternative sampling schemes and enables fast and reliable fully Bayesian inferences with tens of thousand regressors.},
    issn = {1369-7412},
    doi = {10.1111/rssb.12316},
    url = {https://doi.org/10.1111/rssb.12316},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/81/3/489/49269619/jrsssb\_81\_3\_489.pdf},
}
@article{Brown+1998,
author = {Brown, P. J. and Vannucci, M. and Fearn, T.},
title = {Bayesian wavelength selection in multicomponent analysis},
journal = {Journal of Chemometrics},
volume = {12},
number = {3},
pages = {173-182},
keywords = {multivariate regression, Bayesian wavelength selection, Markov chain Monte Carlo (MCMC), Metropolis algorithm, NIR spectroscopy, multicomponent analysis, selection bias, model averaging},
doi = {https://doi.org/10.1002/(SICI)1099-128X(199805/06)12:3<173::AID-CEM505>3.0.CO;2-0},
url = {https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291099-128X%28199805/06%2912%3A3%3C173%3A%3AAID-CEM505%3E3.0.CO%3B2-0},
eprint = {https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/pdf/10.1002/%28SICI%291099-128X%28199805/06%2912%3A3%3C173%3A%3AAID-CEM505%3E3.0.CO%3B2-0},
abstract = {Abstract Multicomponent analysis attempts to simultaneously predict the ingredients of a mixture. If near-infrared spectroscopy provides the predictor variables, then modern scanning instruments may offer absorbances at a very large number of wavelengths. Although it is perfectly possible to use whole spectrum methods (e.g. PLS, ridge and principal component regression), for a number of reasons it is often desirable to select a small number of wavelengths from which to construct the prediction equation relating absorbances to composition. This paper considers wavelength selection with a view to using the chosen wavelengths to simultaneously predict the compositional ingredients and is therefore an example of multivariate variable selection. It adopts a binary exclusion/inclusion latent variable formulation of selection and uses a Bayesian approach. Problems of search of the vast number of possible selected models are overcome by a Markov chain Monte Carlo sampling technique. © 1998 John Wiley \& Sons, Ltd.},
year = {1998}
}
@article{Yang+2016,
author = {Yun Yang and Martin J. Wainwright and Michael I. Jordan},
title = {{On the computational complexity of high-dimensional Bayesian variable selection}},
volume = {44},
journal = {The Annals of Statistics},
number = {6},
publisher = {Institute of Mathematical Statistics},
pages = {2497 -- 2532},
keywords = {Bayesian variable selection, high-dimensional inference, Markov chain, rapid mixing, spectral gap},
year = {2016},
doi = {10.1214/15-AOS1417},
URL = {https://doi.org/10.1214/15-AOS1417}
}
@article{Tierney1998,
 ISSN = {10505164},
 URL = {http://www.jstor.org/stable/2667233},
 abstract = {The Metropolis-Hastings algorithm is a method of constructing a reversible Markov transition kernel with a specified invariant distribution. This note describes necessary and sufficient conditions on the candidate generation kernel and the acceptance probability function for the resulting transition kernel and invariant distribution to satisfy the detailed balance conditions. A simple general formulation is used that covers a range of special cases treated separately in the literature. In addition, results on a useful partial ordering of finite state space reversible transition kernels are extended to general state spaces and used to compare the performance of two approaches to using mixtures in Metropolis-Hastings kernels.},
 author = {Luke Tierney},
 journal = {The Annals of Applied Probability},
 number = {1},
 pages = {1--9},
 publisher = {Institute of Mathematical Statistics},
 title = {A Note on Metropolis-Hastings Kernels for General State Spaces},
 urldate = {2024-12-29},
 volume = {8},
 year = {1998}
}
@article{Zhou+2022,
    author = {Zhou, Quan and Yang, Jun and Vats, Dootika and Roberts, Gareth O. and Rosenthal, Jeffrey S.},
    title = {Dimension-Free Mixing for High-Dimensional Bayesian Variable Selection},
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {84},
    number = {5},
    pages = {1751-1784},
    year = {2022},
    month = {10},
    abstract = {Yang et al. proved that the symmetric random walk Metropolis–Hastings algorithm for Bayesian variable selection is rapidly mixing under mild high-dimensional assumptions. We propose a novel Markov chain Monte Carlo (MCMC) sampler using an informed proposal scheme, which we prove achieves a much faster mixing time that is independent of the number of covariates, under the assumptions of Yang et al. To the best of our knowledge, this is the first high-dimensional result which rigorously shows that the mixing rate of informed MCMC methods can be fast enough to offset the computational cost of local posterior evaluation. Motivated by the theoretical analysis of our sampler, we further propose a new approach called ‘two-stage drift condition’ to studying convergence rates of Markov chains on general state spaces, which can be useful for obtaining tight complexity bounds in high-dimensional settings. The practical advantages of our algorithm are illustrated by both simulation studies and real data analysis.},
    issn = {1369-7412},
    doi = {10.1111/rssb.12546},
    url = {https://doi.org/10.1111/rssb.12546},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/84/5/1751/49458965/jrsssb\_84\_5\_1751.pdf},
}
@misc{Ding2024LinearModels,
      title={Linear Model and Extensions}, 
      author={Peng Ding},
      year={2024},
      eprint={2401.00649},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
      url={https://arxiv.org/abs/2401.00649}, 
}
@inbook{McFadden1974,
  author = {Daniel McFadden},
  chapter = {Conditional Logit Analysis of Qualitative Choice Behavior},
  editor = {P. Zarembka},
  pages = {105-142},
  publisher = {Academic Press},
  title = {Frontiers in Econometrics},
  year = {1974},
  url = {https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf},
}
@article{Yule1907,
author = {Yule, George Udny},
title = {On the theory of correlation for any number of variables, treated by a new system of notation},
journal = {Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character},
volume = {79},
number = {529},
pages = {182-193},
year = {1907},
doi = {10.1098/rspa.1907.0028},
URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rspa.1907.0028},
eprint = {https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.1907.0028}
}
@TechReport{Lovell1963,
  author={Michael C. Lovell},
  title={{Seasonal Adjustment of Economic Time Series and Multiple Regression}},
  year=1963,
  institution={Cowles Foundation for Research in Economics, Yale University},
  type={Cowles Foundation Discussion Papers},
  url={https://ideas.repec.org/p/cwl/cwldpp/151.html},
  number={151},
  abstract={After demonstrating that any nontrivial technique for seasonally adjusting time series inevitably leads to certain distortions of the data, an effort is made to provide explicit motivation for the process of seasonal adjustment for purposes of appraising current economic conditions. Inherent advantages in terms of certain consistency requirements of a least square procedure for seasonal adjustment are pointed out. Problems encountered by the econometrician when seasonally adjusted time series are to be employed in regression analysis are also explored. The dummy variable technique for dealing with seasonal fluctuations is generalized to encompass a flexible pattern of seasonal movement. It is argued that when seasonally adjusted data rather than the dummy variable procedure are employed, there is an inherent tendency to overstate the significance of regression coefficients; a correction procedure is suggested. Consideration is given to certain special problems created by autocorrelated residuals when seasonally adjusted data are utilized in regression analysis.},
  keywords={},
  doi={},
}
@article{Frisch-Waugh1933,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/1907330},
 author = {Ragnar Frisch and Frederick V. Waugh},
 journal = {Econometrica},
 number = {4},
 pages = {387--401},
 publisher = {[Wiley, Econometric Society]},
 title = {Partial Time Regressions as Compared with Individual Trends},
 urldate = {2024-12-29},
 volume = {1},
 year = {1933}
}
@article{Cochran1938,
 ISSN = {14666162},
 URL = {http://www.jstor.org/stable/2983654},
 author = {W. G. Cochran},
 journal = {Supplement to the Journal of the Royal Statistical Society},
 number = {2},
 pages = {171--176},
 publisher = {[Oxford University Press, Royal Statistical Society]},
 title = {The Omission or Addition of an Independent Variate in Multiple Linear Regression},
 urldate = {2024-12-29},
 volume = {5},
 year = {1938}
}
@article{Simpson1951,
 ISSN = {00359246},
 URL = {http://www.jstor.org/stable/2984065},
 abstract = {The definition of second order interaction in a (2 × 2 × 2) table given by Bartlett is accepted, but it is shown by an example that the vanishing of this second order interaction does not necessarily justify the mechanical procedure of forming the three component 2 × 2 tables and testing each of these for significance by standard methods.},
 author = {E. H. Simpson},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {2},
 pages = {238--241},
 publisher = {[Royal Statistical Society, Oxford University Press]},
 title = {The Interpretation of Interaction in Contingency Tables},
 urldate = {2024-12-29},
 volume = {13},
 year = {1951}
}
@article{White1980,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/1912934},
 abstract = {This paper presents a parameter covariance matrix estimator which is consistent even when the disturbances of a linear regression model are heteroskedastic. This estimator does not depend on a formal model of the structure of the heteroskedasticity. By comparing the elements of the new estimator to those of the usual covariance estimator, one obtains a direct test for heteroskedasticity, since in the absence of heteroskedasticity, the two estimators will be approximately equal, but will generally diverge otherwise. The test has an appealing least squares interpretation.},
 author = {Halbert White},
 journal = {Econometrica},
 number = {4},
 pages = {817--838},
 publisher = {[Wiley, Econometric Society]},
 title = {A Heteroskedasticity-Consistent Covariance Matrix Estimator and a Direct Test for Heteroskedasticity},
 urldate = {2024-12-29},
 volume = {48},
 year = {1980}
}
@inproceedings{Eicker1967,
  author = {Friedhelm Eicker},
  year = {1967},
  title = {Limit theorems for regressions with unequal and dependent errors},
  booktitle = {Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics},
  volume = {1},
  pages = {59-82},
  editor = {Lucien M. Le{\ }Cam and Jerzy Neyman},
  url = {https://projecteuclid.org/proceedings/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Fifth-Berkeley-Symposium-on-Mathematical-Statistics-and/Chapter/Limit-theorems-for-regressions-with-unequal-and-dependent-errors/bsmsp/1200512981}
}
@inproceedings{Huber1967,
  author = {Peter J. Huber},
  year = {1967},
  title = {The behavior of maximum likelihood estimates under nonstandard conditions},
  booktitle = {Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics},
  volume = {1},
  pages = {221-233},
  editor = {Lucien M. Le{\ }Cam and Jerzy Neyman},
  url = {https://projecteuclid.org/proceedings/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Fifth-Berkeley-Symposium-on-Mathematical-Statistics-and/Chapter/The-behavior-of-maximum-likelihood-estimates-under-nonstandard-conditions/bsmsp/1200512988}
}

@article{Altonji-Segal1996,
 ISSN = {07350015},
 URL = {http://www.jstor.org/stable/1392447},
 abstract = {We examine the small-sample properties of the generalized method of moments estimator applied to models of covariance structures, in which case it is commonly known as the optimal minimum distance (OMD) estimator. We find that OMD is almost always biased downward in absolute value. The bias arises because sampling errors in the second moments are correlated with sampling errors in the weighting matrix used by OMD. Furthermore, OMD is usually dominated by equally weighted minimum distance (EWMD). We also propose an alternative estimator that is unbiased and asymptotically equivalent to OMD. The Monte Carlo evidence indicates, however, that it is usually dominated by EWMD.},
 author = {Joseph G. Altonji and Lewis M. Segal},
 journal = {Journal of Business & Economic Statistics},
 number = {3},
 pages = {353--366},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Small-Sample Bias in GMM Estimation of Covariance Structures},
 urldate = {2024-12-30},
 volume = {14},
 year = {1996}
}
@article{Newey-Smith2004,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/3598854},
 abstract = {In an effort to improve the small sample properties of generalized method of moments (GMM) estimators, a number of alternative estimators have been suggested. These include empirical likelihood (EL), continuous updating, and exponential tilting estimators. We show that these estimators share a common structure, being members of a class of generalized empirical likelihood (GEL) estimators. We use this structure to compare their higher order asymptotic properties. We find that GEL has no asymptotic bias due to correlation of the moment functions with their Jacobian, eliminating an important source of bias for GMM in models with endogeneity. We also find that EL has no asymptotic bias from estimating the optimal weight matrix, eliminating a further important source of bias for GMM in panel data models. We give bias corrected GMM and GEL estimators. We also show that bias corrected EL inherits the higher order property of maximum likelihood, that it is higher order asymptotically efficient relative to the other bias corrected estimators.},
 author = {Whitney K. Newey and Richard J. Smith},
 journal = {Econometrica},
 number = {1},
 pages = {219--255},
 publisher = {[Wiley, Econometric Society]},
 title = {Higher Order Properties of GMM and Generalized Empirical Likelihood Estimators},
 urldate = {2024-12-30},
 volume = {72},
 year = {2004}
}

@article{Liang+2022,
	abstract = {We introduce a framework for efficient Markov chain Monte Carlo algorithms targeting discrete-valued high-dimensional distributions, such as posterior distributions in Bayesian variable selection problems. We show that many recently introduced algorithms, such as the locally informed sampler of Zanella (J Am Stat Assoc 115(530):852--865, 2020), the locally informed with thresholded proposal of Zhou et al. (Dimension-free mixing for high-dimensional Bayesian variable selection, 2021) and the adaptively scaled individual adaptation sampler of Griffin et al. (Biometrika 108(1):53--69, 2021), can be viewed as particular cases within the framework. We then describe a novel algorithm, the adaptive random neighbourhood informed sampler, which combines ideas from these existing approaches. We show using several examples of both real and simulated data-sets that a computationally efficient point-wise implementation (PARNI) provides more reliable inferences on a range of variable selection problems, particularly in the very large p setting.},
	author = {Liang, Xitong and Livingstone, Samuel and Griffin, Jim},
	date = {2022/09/30},
	date-added = {2024-12-30 21:46:09 +0900},
	date-modified = {2024-12-30 21:46:09 +0900},
	doi = {10.1007/s11222-022-10137-8},
	id = {Liang2022},
	isbn = {1573-1375},
	journal = {Statistics and Computing},
	number = {5},
	pages = {84},
	title = {Adaptive random neighbourhood informed Markov chain Monte Carlo for high-dimensional Bayesian variable selection},
	url = {https://doi.org/10.1007/s11222-022-10137-8},
	volume = {32},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1007/s11222-022-10137-8}}
@article{Nishimura+2020,
    author = {Nishimura, Akihiko and Dunson, David B and Lu, Jianfeng},
    title = {Discontinuous Hamiltonian Monte Carlo for discrete parameters and discontinuous likelihoods},
    journal = {Biometrika},
    volume = {107},
    number = {2},
    pages = {365-380},
    year = {2020},
    month = {03},
    abstract = {Hamiltonian Monte Carlo has emerged as a standard tool for posterior computation. In this article we present an extension that can efficiently explore target distributions with discontinuous densities. Our extension in particular enables efficient sampling from ordinal parameters through the embedding of probability mass functions into continuous spaces. We motivate our approach through a theory of discontinuous Hamiltonian dynamics and develop a corresponding numerical solver. The proposed solver is the first of its kind, with a remarkable ability to exactly preserve the Hamiltonian. We apply our algorithm to challenging posterior inference problems to demonstrate its wide applicability and competitive performance.},
    issn = {0006-3444},
    doi = {10.1093/biomet/asz083},
    url = {https://doi.org/10.1093/biomet/asz083},
    eprint = {https://academic.oup.com/biomet/article-pdf/107/2/365/33218134/asz083.pdf},
}
@article{Fernandez+2001,
title = {Benchmark priors for Bayesian model averaging},
journal = {Journal of Econometrics},
volume = {100},
number = {2},
pages = {381-427},
year = {2001},
issn = {0304-4076},
doi = {https://doi.org/10.1016/S0304-4076(00)00076-2},
url = {https://www.sciencedirect.com/science/article/pii/S0304407600000762},
author = {Carmen Fernández and Eduardo Ley and Mark F.J. Steel},
keywords = {Bayes factors, Markov chain Monte Carlo, Posterior odds, Prior elicitation},
abstract = {In contrast to a posterior analysis given a particular sampling model, posterior model probabilities in the context of model uncertainty are typically rather sensitive to the specification of the prior. In particular, ‘diffuse’ priors on model-specific parameters can lead to quite unexpected consequences. Here we focus on the practically relevant situation where we need to entertain a (large) number of sampling models and we have (or wish to use) little or no subjective prior information. We aim at providing an ‘automatic’ or ‘benchmark’ prior structure that can be used in such cases. We focus on the normal linear regression model with uncertainty in the choice of regressors. We propose a partly non-informative prior structure related to a natural conjugate g-prior specification, where the amount of subjective information requested from the user is limited to the choice of a single scalar hyperparameter g0j. The consequences of different choices for g0j are examined. We investigate theoretical properties, such as consistency of the implied Bayesian procedure. Links with classical information criteria are provided. More importantly, we examine the finite sample implications of several choices of g0j in a simulation study. The use of the MC3 algorithm of Madigan and York (Int. Stat. Rev. 63 (1995) 215), combined with efficient coding in Fortran, makes it feasible to conduct large simulations. In addition to posterior criteria, we shall also compare the predictive performance of different priors. A classic example concerning the economics of crime will also be provided and contrasted with results in the literature. The main findings of the paper will lead us to propose a ‘benchmark’ prior specification in a linear regression context with model uncertainty.}
}

@article{Liang+2008,
	annote = {doi: 10.1198/016214507000001337},
	author = {Liang ,Feng and Paulo ,Rui and Molina ,German and Clyde ,Merlise A and Berger ,Jim O},
	date = {2008/03/01},
	date-added = {2024-12-30 22:32:38 +0900},
	date-modified = {2024-12-30 22:32:38 +0900},
	doi = {10.1198/016214507000001337},
	isbn = {0162-1459},
	journal = {Journal of the American Statistical Association},
	journal1 = {Journal of the American Statistical Association},
	journal2 = {Journal of the American Statistical Association},
	month = {03},
	number = {481},
	pages = {410--423},
	publisher = {ASA Website},
	title = {Mixtures of g Priors for Bayesian Variable Selection},
	type = {doi: 10.1198/016214507000001337},
	url = {https://doi.org/10.1198/016214507000001337},
	volume = {103},
	year = {2008},
	year1 = {2008},
	bdsk-url-1 = {https://doi.org/10.1198/016214507000001337}}
@article{Lay-Steel2009,
author = {Ley, Eduardo and Steel, Mark F.J.},
title = {On the effect of prior assumptions in Bayesian model averaging with applications to growth regression},
journal = {Journal of Applied Econometrics},
volume = {24},
number = {4},
pages = {651-674},
doi = {https://doi.org/10.1002/jae.1057},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.1057},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jae.1057},
abstract = {Abstract We consider the problem of variable selection in linear regression models. Bayesian model averaging has become an important tool in empirical settings with large numbers of potential regressors and relatively limited numbers of observations. We examine the effect of a variety of prior assumptions on the inference concerning model size, posterior inclusion probabilities of regressors and on predictive performance. We illustrate these issues in the context of cross-country growth regressions using three datasets with 41–67 potential drivers of growth and 72–93 observations. Finally, we recommend priors for use in this and related contexts. Copyright © 2009 John Wiley \& Sons, Ltd.},
year = {2009}
}
@article{Shang-Clayton2011,
title = {Consistency of Bayesian linear model selection with a growing number of parameters},
journal = {Journal of Statistical Planning and Inference},
volume = {141},
number = {11},
pages = {3463-3474},
year = {2011},
issn = {0378-3758},
doi = {https://doi.org/10.1016/j.jspi.2011.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0378375811001947},
author = {Zuofeng Shang and Murray K. Clayton},
keywords = {Bayesian model selection, Growing number of parameters, Posterior model consistency, Consistency of Bayes factor, Consistency of posterior odds ratio, -priors, Gibbs sampling},
abstract = {Linear models with a growing number of parameters have been widely used in modern statistics. One important problem about this kind of model is the variable selection issue. Bayesian approaches, which provide a stochastic search of informative variables, have gained popularity. In this paper, we will study the asymptotic properties related to Bayesian model selection when the model dimension p is growing with the sample size n. We consider p≤n and provide sufficient conditions under which: (1) with large probability, the posterior probability of the true model (from which samples are drawn) uniformly dominates the posterior probability of any incorrect models; and (2) the posterior probability of the true model converges to one in probability. Both (1) and (2) guarantee that the true model will be selected under a Bayesian framework. We also demonstrate several situations when (1) holds but (2) fails, which illustrates the difference between these two properties. Finally, we generalize our results to include g-priors, and provide simulation examples to illustrate the main results.}
}
@article{Griffin+2021,
    author = {Griffin, J E and Łatuszyński, K G and Steel, M F J},
    title = {In search of lost mixing time: adaptive Markov chain Monte Carlo schemes for Bayesian variable selection with very large p},
    journal = {Biometrika},
    volume = {108},
    number = {1},
    pages = {53-69},
    year = {2021},
    month = {10},
    abstract = {The availability of datasets with large numbers of variables is rapidly increasing. The effective application of Bayesian variable selection methods for regression with these datasets has proved difficult since available Markov chain Monte Carlo methods do not perform well in typical problem sizes of interest. We propose new adaptive Markov chain Monte Carlo algorithms to address this shortcoming. The adaptive design of these algorithms exploits the observation that in large-\$p\$, small-\$n\$ settings, the majority of the \$p\$ variables will be approximately uncorrelated a posteriori. The algorithms adaptively build suitable nonlocal proposals that result in moves with squared jumping distance significantly larger than standard methods. Their performance is studied empirically in high-dimensional problems and speed-ups of up to four orders of magnitude are observed.},
    issn = {0006-3444},
    doi = {10.1093/biomet/asaa055},
    url = {https://doi.org/10.1093/biomet/asaa055},
    eprint = {https://academic.oup.com/biomet/article-pdf/108/1/53/36441124/asaa055.pdf},
}
@article{Ghosh+2018,
author = {Joyee Ghosh and Yingbo Li and Robin Mitra},
title = {{On the Use of Cauchy Prior Distributions for Bayesian Logistic Regression}},
volume = {13},
journal = {Bayesian Analysis},
number = {2},
publisher = {International Society for Bayesian Analysis},
pages = {359 -- 383},
keywords = {binary regression, existence of posterior mean, Markov chain Monte Carlo, probit regression, separation, slow mixing},
year = {2018},
doi = {10.1214/17-BA1051},
URL = {https://doi.org/10.1214/17-BA1051}
}
@misc{Piironen-Vehtari2015,
      title={Projection predictive variable selection using Stan+R}, 
      author={Juho Piironen and Aki Vehtari},
      year={2015},
      eprint={1508.02502},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
      url={https://arxiv.org/abs/1508.02502}, 
}
@article{碓井知子2015,
  author = {碓井知子},
  year = {2015},
  title = {アルブミン尿・蛋白尿の疫学，臨床研究},
  journal = {日本腎臓学会誌},
  volume = {57},
  number = {8},
  pages = {1275-1280},
  url = {https://jsn.or.jp/journal/_3030.php}
}
@article{岡田浩一2019,
  title={I．DKDの疾患概念と腎臓専門医への紹介基準},
  author={岡田浩一},
  journal={日本内科学会雑誌},
  volume={108},
  number={5},
  pages={901-906},
  year={2019},
  doi={10.2169/naika.108.901}
}

@article{Heerspink+2015,
	author = {Lambers Heerspink, Hiddo J. and Kr{\"o}pelin, Tobias F. and Hoekman, Jarno and de Zeeuw, Dick},
	date-added = {2025-01-05 14:56:46 +0900},
	date-modified = {2025-01-05 14:56:46 +0900},
	id = {00001751-201508000-00030},
	isbn = {1046-6673},
	journal = {Journal of the American Society of Nephrology},
	keywords = {albuminuria; clinical trial; ESRD; proteinuria},
	n2 = {Albuminuria has been proposed as a surrogate end point in randomized clinical trials of renal disease progression. Most evidence comes from observational analyses showing that treatment-induced short-term changes in albuminuria correlate with risk change for ESRD. However, such studies are prone to selection bias and residual confounding. To minimize this bias, we performed a meta-analysis of clinical trials to correlate the placebo-corrected drug effect on albuminuria and ESRD to more reliably delineate the association between changes in albuminuria and ESRD. MEDLINE and EMBASE were searched for clinical trials reported between 1950 and April 2014. Included trials had a mean follow-up of ≥1000 patient-years, reported ESRD outcomes, and measured albuminuria at baseline and during follow-up. Twenty-one clinical trials involving 78,342 patients and 4183 ESRD events were included. Median time to first albuminuria measurement was 6 months. Fourteen trials tested the effect of renin-angiotensin-aldosterone-system inhibitors and seven trials tested other interventions. We observed variability across trials in the treatment effect on albuminuria (range, −1.3{\%} to −32.1{\%}) and ESRD (range, −55{\%} to +35{\%} risk change). Meta-regression analysis revealed that the placebo-adjusted treatment effect on albuminuria significantly correlated with the treatment effect on ESRD: for each 30{\%} reduction in albuminuria, the risk of ESRD decreased by 23.7{\%} (95{\%} confidence interval, 11.4{\%} to 34.2{\%}; P=0.001). The association was consistent regardless of drug class (P=0.73) or other patient or trial characteristics. These findings suggest albuminuria may be a valid substitute for ESRD in many circumstances, even taking into account possible other drug-specific effects that may alter renal outcomes.},
	number = {8},
	title = {Drug-Induced Reduction in Albuminuria Is Associated with Subsequent Renoprotection: A Meta-Analysis},
	url = {https://journals.lww.com/jasn/fulltext/2015/08000/drug_induced_reduction_in_albuminuria_is.30.aspx},
	volume = {26},
	year = {2015},
	bdsk-url-1 = {https://journals.lww.com/jasn/fulltext/2015/08000/drug_induced_reduction_in_albuminuria_is.30.aspx}}
@article{竹内真登-猪狩良介2022,
  title={文脈効果を考慮したコンジョイント分析による購買予測},
  author={竹内真登 and 猪狩良介},
  journal={流通研究},
  volume={24},
  number={2},
  pages={17-32},
  year={2022},
  doi={10.5844/jsmd.24.2_17}
}
@article{Michel+2020,
author = {Manon Michel and Alain Durmus and Stéphane Sénécal},
title = {Forward Event-Chain Monte Carlo: Fast Sampling by Randomness Control in Irreversible Markov Chains},
journal = {Journal of Computational and Graphical Statistics},
volume = {29},
number = {4},
pages = {689--702},
year = {2020},
publisher = {ASA Website},
doi = {10.1080/10618600.2020.1750417},
URL = {https://doi.org/10.1080/10618600.2020.1750417}
}
@unpublished{Korba-Salim2022,
  author = {Anna Korba and Adil Salim},
  year = {2022},
  title = {Sampling as First-Order Optimization over a space of probability measures},
  note = {ICML Tutorial},
  url = {https://icml.cc/virtual/2022/tutorial/18437}
}

@InProceedings{Wibisono2018,
  title = 	 {Sampling as optimization in the space of measures: The Langevin dynamics as a composite optimization problem},
  author =       {Wibisono, Andre},
  booktitle = 	 {Proceedings of the 31st  Conference On Learning Theory},
  pages = 	 {2093--3027},
  year = 	 {2018},
  editor = 	 {Bubeck, Sébastien and Perchet, Vianney and Rigollet, Philippe},
  volume = 	 {75},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v75/wibisono18a/wibisono18a.pdf},
  url = 	 {https://proceedings.mlr.press/v75/wibisono18a.html},
  abstract = 	 {We study sampling as optimization in the space of measures. We focus on gradient flow-based optimization with the Langevin dynamics as a case study. We investigate the source of the bias of the unadjusted Langevin algorithm (ULA) in discrete time, and consider how to remove or reduce the bias. We point out the difficulty is that the heat flow is exactly solvable, but neither its forward nor backward method is implementable in general, except for Gaussian data. We propose the symmetrized Langevin algorithm (SLA), which should have a smaller bias than ULA, at the price of implementing a proximal gradient step in space. We show SLA is in fact consistent for Gaussian target measure, whereas ULA is not. We also illustrate various algorithms explicitly for Gaussian target measure with Gaussian data, including gradient descent, proximal gradient, and Forward-Backward, and show they are all consistent.}
}

@InProceedings{Dalalyan2017,
  title = 	 {Further and stronger analogy between sampling and optimization: Langevin Monte Carlo and gradient descent},
  author = 	 {Dalalyan, Arnak},
  booktitle = 	 {Proceedings of the 2017 Conference on Learning Theory},
  pages = 	 {678--689},
  year = 	 {2017},
  editor = 	 {Kale, Satyen and Shamir, Ohad},
  volume = 	 {65},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {07--10 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v65/dalalyan17a/dalalyan17a.pdf},
  url = 	 {https://proceedings.mlr.press/v65/dalalyan17a.html},
  abstract = 	 {In this paper, we revisit the recently established theoretical guarantees for the convergence of the Langevin Monte Carlo algorithm of sampling from a smooth and (strongly) log-concave density. We improve the existing results when the convergence is measured in the Wasserstein distance and provide further insights on the very tight relations between, on the one hand, the Langevin Monte Carlo for sampling and, on the other hand, the gradient descent for optimization. Finally, we also establish guarantees for the convergence of a version of the Langevin Monte Carlo algorithm that is based on noisy evaluations of the gradient.}
}
@inproceedings{Chehab+2024,
title={Provable Convergence and Limitations of Geometric Tempering for Langevin Dynamics},
author={Omar Chehab and Anna Korba and Austin Stromme and Adrien Vacher},
booktitle={Submitted to The Thirteenth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=DZcmz9wU0i},
}

@article{Chatterjee2007,
	abstract = {We introduce a version of Stein's method for proving concentration and moment inequalities in problems with dependence. Simple illustrative examples from combinatorics, physics, and mathematical statistics are provided.},
	author = {Chatterjee, Sourav},
	date = {2007/05/01},
	date-added = {2025-01-11 11:01:10 +0900},
	date-modified = {2025-01-11 11:01:10 +0900},
	doi = {10.1007/s00440-006-0029-y},
	id = {Chatterjee2007},
	isbn = {1432-2064},
	journal = {Probability Theory and Related Fields},
	number = {1},
	pages = {305--321},
	title = {Stein's method for concentration inequalities},
	url = {https://doi.org/10.1007/s00440-006-0029-y},
	volume = {138},
	year = {2007},
	bdsk-url-1 = {https://doi.org/10.1007/s00440-006-0029-y}}

@article{Stuart-Wolfram2020,
	abstract = { Discrete optimal transportation problems arise in various contexts in engineering, the sciences, and the social sciences. Often the underlying cost criterion is unknown, or only partly known, and the observed optimal solutions are corrupted by noise. In this paper we propose a systematic approach to infer unknown costs from noisy observations of optimal transportation plans. The algorithm requires only the ability to solve the forward optimal transport problem, which is a linear program, and to generate random numbers. It has a Bayesian interpretation and may also be viewed as a form of stochastic optimization. We illustrate the developed methodologies using the example of international migration flows. Reported migration flow data captures (noisily) the number of individuals moving from one country to another in a given period of time. It can be interpreted as a noisy observation of an optimal transportation map, with costs related to the geographical position of countries. We use a graph-based formulation of the problem, with countries at the nodes of graphs and nonzero weighted adjacencies only on edges between countries which share a border. We use the proposed algorithm to estimate the weights, which represent cost of transition, and to quantify uncertainty in these weights. },
	author = {Stuart, Andrew M. and Wolfram, Marie-Therese},
	doi = {10.1137/19M1261122},
	eprint = {https://doi.org/10.1137/19M1261122},
	journal = {SIAM Journal on Applied Mathematics},
	number = {1},
	pages = {599-619},
	title = {Inverse Optimal Transport},
	url = {https://doi.org/10.1137/19M1261122},
	volume = {80},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1137/19M1261122}}

@InProceedings{Chiu+2022,
  title = 	 {Discrete Probabilistic Inverse Optimal Transport},
  author =       {Chiu, Wei-Ting and Wang, Pei and Shafto, Patrick},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {3925--3946},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/chiu22b/chiu22b.pdf},
  url = 	 {https://proceedings.mlr.press/v162/chiu22b.html},
  abstract = 	 {Inverse Optimal Transport (IOT) studies the problem of inferring the underlying cost that gives rise to an observation on coupling two probability measures. Couplings appear as the outcome of matching sets (e.g. dating) and moving distributions (e.g. transportation). Compared to Optimal transport (OT), the mathematical theory of IOT is undeveloped. We formalize and systematically analyze the properties of IOT using tools from the study of entropy-regularized OT. Theoretical contributions include characterization of the manifold of cross-ratio equivalent costs, the implications of model priors, and derivation of an MCMC sampler. Empirical contributions include visualizations of cross-ratio equivalent effect on basic examples, simulations validating theoretical results and experiments on real world data.}
}

@article{Getoor1999,
	author = {Ronald Getoor},
	doi = {10.1214/EJP.v4-56},
	journal = {Electronic Journal of Probability},
	keywords = {generators, Markov processes, Schr{\"o}dinger equations, smooth measures},
	number = {none},
	pages = {1 -- 23},
	publisher = {Institute of Mathematical Statistics and Bernoulli Society},
	title = {{An Extended Generator and Schr{\"o}dinger Equations}},
	url = {https://doi.org/10.1214/EJP.v4-56},
	volume = {4},
	year = {1999},
	bdsk-url-1 = {https://doi.org/10.1214/EJP.v4-56}}

@article{Wu-Robert2020,
	abstract = {We derive a novel non-reversible, continuous-time Markov chain Monte Carlo sampler, called Coordinate Sampler, based on a piecewise deterministic Markov process, which is a variant of the Zigzag sampler of Bierkens et al. (Ann Stat 47(3):1288--1320, 2019). In addition to providing a theoretical validation for this new simulation algorithm, we show that the Markov chain it induces exhibits geometrical ergodicity convergence, for distributions whose tails decay at least as fast as an exponential distribution and at most as fast as a Gaussian distribution. Several numerical examples highlight that our coordinate sampler is more efficient than the Zigzag sampler, in terms of effective sample size.},
	author = {Wu, Changye and Robert, Christian P.},
	date = {2020/05/01},
	date-added = {2025-01-12 16:11:15 +0900},
	date-modified = {2025-01-12 16:11:15 +0900},
	doi = {10.1007/s11222-019-09913-w},
	id = {Wu2020},
	isbn = {1573-1375},
	journal = {Statistics and Computing},
	number = {3},
	pages = {721--730},
	title = {Coordinate sampler: a non-reversible Gibbs-like MCMC sampler},
	url = {https://doi.org/10.1007/s11222-019-09913-w},
	volume = {30},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1007/s11222-019-09913-w}}
@article{Bierkens-Kamatani-Roberts2024,
  author = {Joris Bierkens and Kengo Kamatani and Gareth O. Roberts},
  year = {2025},
  title = {Scaling of Piecewise Deterministic Monte Carlo for Anisotropic Targets},
  journal = {Bernoulli},
  volume = {},
  number = {},
  pages = {},
  url = {}
}
@book{Liggett2010,
  author = {Thomas M. Liggett},
  year = {2010},
  title = {Continuous Time Markov Processes: An Introduction},
  series = {Graduate Studies in Mathematics},
  volume = {113},
  edition = {},
  url = {https://bookstore.ams.org/gsm-113},
  publisher = {American Mathematical Society}
}

@book{Pavliotis-Stuart2008,
  author = {Grigorios A. Pavliotis and Andrew M. Stuart},
  year = {2008},
  title = {Multiscale Methods: Averaging and Homogenization},
  series = {Texts in Applied Mathematics},
  volume = {},
  edition = {},
  url = {https://doi.org/10.1007/978-0-387-73829-1},
  publisher = {Springer New York}
}
@article{Chung+1987,
author = {F. R. K. Chung and Persi Diaconis and R. L. Graham},
title = {{Random Walks Arising in Random Number Generation}},
volume = {15},
journal = {The Annals of Probability},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1148 -- 1165},
keywords = {discrete Fourier analysis, Fourier analysis, random number generation, Random walk},
year = {1987},
doi = {10.1214/aop/1176992088},
URL = {https://doi.org/10.1214/aop/1176992088}
}
@misc{Neal2004,
      title={Improving Asymptotic Variance of MCMC Estimators: Non-reversible Chains are Better}, 
      author={Radford M. Neal},
      year={2004},
      eprint={math/0407281},
      archivePrefix={arXiv},
      primaryClass={math.PR},
      url={https://arxiv.org/abs/math/0407281}, 
}
@article{Diaconis2013,
author = {Persi Diaconis},
title = {{Some things we’ve learned (about Markov chain Monte Carlo)}},
volume = {19},
journal = {Bernoulli},
number = {4},
publisher = {Bernoulli Society for Mathematical Statistics and Probability},
pages = {1294 -- 1305},
keywords = {Markov chains, nonreversible chains, rates of convergence},
year = {2013},
doi = {10.3150/12-BEJSP09},
URL = {https://doi.org/10.3150/12-BEJSP09}
}

@misc{Sanz-Alonso-Al-Ghattas2024,
      title={A First Course in Monte Carlo Methods}, 
      author={Daniel Sanz-Alonso and Omar Al-Ghattas},
      year={2024},
      eprint={2405.16359},
      archivePrefix={arXiv},
      primaryClass={stat.CO},
      url          = {https://arxiv.org/abs/2405.16359},
}

@article{Caracciolo+1990,
	abstract = {We study a new Monte Carlo algorithm for generating self-avoiding walks with variable length (controlled by a fugacityβ) and fixed endpoints. The algorithm is a hybrid of local (BFACF) and nonlocal (cut-and-paste) moves. We find that the critical slowing-down, measured in units of computer time, is reduced compared to the pure BFACF algorithm:τCPU∼〈N〉≈2.3 versus 〈N〉≈3.0. We also prove some rigorous bounds on the autocorrelation time for these and related Monte Carlo algorithms.},
	author = {Caracciolo, Sergio and Pelissetto, Andrea and Sokal, Alan D.},
	date = {1990/07/01},
	date-added = {2025-01-26 18:48:47 +0900},
	date-modified = {2025-01-26 18:48:47 +0900},
	doi = {10.1007/BF01013668},
	id = {Caracciolo1990},
	isbn = {1572-9613},
	journal = {Journal of Statistical Physics},
	number = {1},
	pages = {1--53},
	title = {Nonlocal Monte Carlo algorithm for self-avoiding walks with fixed endpoints},
	url = {https://doi.org/10.1007/BF01013668},
	volume = {60},
	year = {1990},
	bdsk-url-1 = {https://doi.org/10.1007/BF01013668}}

@article{Donsker-Varadhan1975I,
	author = {Donsker, M. D. and Varadhan, S. R. S.},
	doi = {https://doi.org/10.1002/cpa.3160280102},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpa.3160280102},
	journal = {Communications on Pure and Applied Mathematics},
	number = {1},
	pages = {1-47},
	title = {Asymptotic evaluation of certain markov process expectations for large time, I},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.3160280102},
	volume = {28},
	year = {1975},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.3160280102},
	bdsk-url-2 = {https://doi.org/10.1002/cpa.3160280102}}

@article{Beskos+2018,
	author = {Alexandros Beskos and Gareth Roberts and Alexandre Thiery and Natesh Pillai},
	doi = {10.1214/18-AAP1380},
	journal = {The Annals of Applied Probability},
	keywords = {diffusion limit, generator, Manifold, Random-walk metropolis},
	number = {5},
	pages = {2966 -- 3001},
	publisher = {Institute of Mathematical Statistics},
	title = {{Asymptotic analysis of the random walk Metropolis algorithm on ridged densities}},
	url = {https://doi.org/10.1214/18-AAP1380},
	volume = {28},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1214/18-AAP1380}}
@article{Durmus+2021,
author = {Alain Durmus and Arnaud Guillin and Pierre Monmarch{\'e}},
title = {{Piecewise deterministic Markov processes and their invariant measures}},
volume = {57},
journal = {Annales de l'Institut Henri Poincaré, Probabilités et Statistiques},
number = {3},
publisher = {Institut Henri Poincaré},
pages = {1442 -- 1475},
keywords = {Bouncy particle sampler, generator, invariant measure, PDMP, synchronous coupling},
year = {2021},
doi = {10.1214/20-AIHP1125},
URL = {https://doi.org/10.1214/20-AIHP1125}
}
@article{Azais+2014,
	author = {Romain Azaïs and Jean-Baptiste Bardet and Alexandre Génadot and Nathalie Krell and Pierre-André Zitt},
	title = {Piecewise deterministic Markov process — recent results},
	DOI= "10.1051/proc/201444017",
	url= "https://doi.org/10.1051/proc/201444017",
	journal = {ESAIM: Proc.},
	year = 2014,
	volume = 44,
	pages = "276-290",
	month = "",
}
@article{Faulkner+2018,
    author = {Faulkner, Michael F. and Qin, Liang and Maggs, A. C. and Krauth, Werner},
    title = {All-atom computations with irreversible Markov chains},
    journal = {The Journal of Chemical Physics},
    volume = {149},
    number = {6},
    pages = {064113},
    year = {2018},
    month = {08},
    abstract = {We apply the irreversible event-chain Monte Carlo (ECMC) algorithm to the simulation of dense all-atom systems with long-range Coulomb interactions. ECMC is event-driven and exactly samples the Boltzmann distribution. It neither uses time-step approximations nor spatial cutoffs on the range of the interaction potentials. Most importantly, it need not evaluate the total Coulomb potential and thus circumvents the major computational bottleneck of traditional approaches. It only requires the derivatives of the two-particle Coulomb potential, for which we discuss mutually consistent choices. ECMC breaks up the total interaction potential into factors. For particle systems made up of neutral dipolar molecules, we demonstrate the superior performance of dipole–dipole factors that do not decompose the Coulomb potential beyond the two-molecule level. We demonstrate that these long-range factors can nevertheless lead to local lifting schemes, where subsequently moved particles are mostly close to each other. For the simple point-charge water model with flexible molecules (SPC/Fw), which combines the long-ranged intermolecular Coulomb potential with hydrogen–oxygen bond-length vibrations, a flexible hydrogen–oxygen–hydrogen bond angle, and Lennard-Jones oxygen–oxygen potentials, we break up the potential into factors containing between two and six particles. For this all-atom liquid-water model, we demonstrate that the computational complexity of ECMC scales very well with the system size. This is achieved in a pure particle–particle framework, without the interpolating mesh required for the efficient implementation of other modern Coulomb algorithms. Finally, we discuss prospects and challenges for ECMC and outline several future applications.},
    issn = {0021-9606},
    doi = {10.1063/1.5036638},
    url = {https://doi.org/10.1063/1.5036638},
    eprint = {https://pubs.aip.org/aip/jcp/article-pdf/doi/10.1063/1.5036638/13501056/064113\_1\_online.pdf},
}
@misc{PDMPFlux2025,
  author = {Hirofumi Shiba},
  howpublished = {Package Release},
  title = {PDMPFlux v0.3.3},
  year = {2025},
  url = {https://doi.org/10.5281/zenodo.14792019},
}

@article{Gangopadhyay-Muhkerjee2021,
	author = {Ujan Gangopadhyay and Gourab Mukherjee},
	doi = {10.1214/21-EJS1818},
	journal = {Electronic Journal of Statistics},
	keywords = {discrete priors, information loss, minimax risk, predictive density estimation, predictive inference, Sparsity},
	number = {1},
	pages = {1636 -- 1660},
	publisher = {Institute of Mathematical Statistics and Bernoulli Society},
	title = {{On discrete priors and sparse minimax optimal predictive densities}},
	url = {https://doi.org/10.1214/21-EJS1818},
	volume = {15},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1214/21-EJS1818}}

@article{高知恵+2023,
  author = {高知恵 and 千葉貴子 and 中根祥子 and 谷口朱子 and 北條渉 and 中嶋有加里 and 古山美穂 and 山田加奈子 and 渡邊香織},
  year = {2023},
  title = {在留外国人褥婦への保健指導を実践する助産師の思いと心理的ストレス - 尿中バイオピリンと心理尺度による横断的研究 -},
  journal = {国際臨床医学会雑誌},
  volume = {7},
  number = {1},
  pages = {22-28},
  url = {https://mol.medicalonline.jp/archive/search?jo=fm0kokus&ye=2023&vo=7&issue=1}
}
@article{Tada+2020,
	annote = {doi: 10.1016/j.heliyon.2019.e03138},
	author = {Tada, Satoshi and Shiota, Atsuko and Hayashi, Hidehiro and Nakamura, Takehiro},
	date = {2020/01/01},
	date-added = {2025-02-27 10:37:52 +0900},
	date-modified = {2025-02-27 10:37:52 +0900},
	doi = {10.1016/j.heliyon.2019.e03138},
	isbn = {2405-8440},
	journal = {Heliyon},
	journal1 = {Heliyon},
	month = {2025/02/26},
	number = {1},
	publisher = {Elsevier},
	title = {Reference urinary biopyrrin level and physiological variation in healthy young adults: relation of stress by learning},
	type = {doi: 10.1016/j.heliyon.2019.e03138},
	url = {https://doi.org/10.1016/j.heliyon.2019.e03138},
	volume = {6},
	year = {2020},
	year1 = {2020},
	bdsk-url-1 = {https://doi.org/10.1016/j.heliyon.2019.e03138}}
@article{Itoh+2012,
  title={Seasonal and Inter-day Variation in Serum High-sensitivity C-reactive Protein in Japanese Male Workers: A Longitudinal Study},
  author={Hiroaki Itoh and Ippei Mori and Yuki Matsumoto and Syou Maki and Yasutaka Ogawa},
  journal={Industrial Health},
  volume={50},
  number={1},
  pages={60-63},
  year={2012},
  doi={10.2486/indhealth.MS1288}
}
@article{石川浩二+2002,
  title={昇進後の中間管理職における心身医学的検討(パネルディスカッションIII/ライフサイクルと現代の諸問題)},
  author={石川 浩二 and 芦原 睦 and 加藤 真二 and 吉原 一文 and 増田 由紀子 and 佐田 彰見 and 森山 裕美 and 山田 恵美},
  journal={心身医学},
  volume={42},
  number={5},
  pages={301-308},
  year={2002},
  doi={10.15064/jjpm.42.5_301}
}
@article{Wake+2022,
author = {Wake, Rei and Araki, Tomoko and Fukushima, Michiyo and Matsuda, Hiroyuki and Inagaki, Takuji and Hayashida, Maiko and Hashioka, Sadayuki and Horiguchi, Jun and Inagaki, Masatoshi and Miyaoka, Tsuyoshi and Oh-Nishi, Arata},
title = {Urinary biopyrrins and free immunoglobin light chains are biomarker candidates for screening at-risk mental state in adolescents},
journal = {Early Intervention in Psychiatry},
volume = {16},
number = {3},
pages = {272-280},
keywords = {at-risk mental state (ARMS), biomarker, biopyrrin, free immunoglobulin light chains (FLCs), oxidative stress, urine},
doi = {https://doi.org/10.1111/eip.13154},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/eip.13154},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/eip.13154},
abstract = {Abstract Background Early diagnosis of individuals' at-risk mental state (ARMS) is important for preventing their pathogenesis or, at least, delaying onset of overt psychosis. Traditional diagnosis of ARMS subjects is mainly based on structured interviews, but future diagnosis would be carried out together with biomarkers. Aim In this study, we report urinary biopyrrins and free immunoglobin light chains κ and λ (κFLC and λFLC) as novel diagnostic biomarker candidates for screening ARMS subjects. Methods Nineteen ARMS subjects and 21 age- and sex-matched healthy controls were enrolled in this study. Inclusion criteria of the ARMS subjects were based on a comprehensive assessment of Structured Interview for Prodromal Syndromes. We compared oxidative stress and immunological markers in the urine of ARMS subjects with those of healthy controls by ELISA protocol. Results Augmentation of biopyrrins and reduction of κFLC and λFLC were found in the ARMS samples, and their diagnostic performance was evaluated by receiver operating characteristic analysis, of which area under the curve was as large as 0.915 in combination. Conclusion Our findings suggest that the ARMS subjects were under higher oxidative stress but lower in B cell activation, and that the combined assay of urinary biopyrrins and free immunoglobulin light chains would be useful for the early detection and screening of ARMS subjects among adolescents.},
year = {2022}
}

@article{Mourad-Gaballah2023,
	author = {Mourad, Basma Hussein and Gaballah, Inas Fawzy},
	date-added = {2025-02-27 15:02:51 +0900},
	date-modified = {2025-02-27 15:02:51 +0900},
	id = {00043764-202301000-00010},
	isbn = {1076-2752},
	journal = {Journal of Occupational and Environmental Medicine},
	keywords = {8-OHdG; biopyrrins; brickfield workers; occupational stress; urinary oxidative biomarkers},
	n2 = {Objectives  The aims of the study are to measure the prevalence and level of occupational stress (OS) and to explore its association with oxidative stress among some brickfield workers.  Methods  Eighty-six brickfield workers and 90 administrative controls were assessed using the Arabic validated version of the Occupational Stress Index. The urinary levels of oxidative biomarkers; 8-hydroxy-2′-deoxyguanosine and biopyrrins were also measured.  Results  The prevalence of moderate and severe OS in addition to the urinary levels of both oxidative biomarkers was significantly higher among the brickfield workers compared with their controls. Both biomarkers levels were significantly and positively correlated with scores of Occupational Stress Index, duration of employment, and with each other. The receiver operating characteristic analysis showed significant specificity and sensitivity of both biomarkers for determining the level of OS.  Conclusions  A significant association between occupational and oxidative stresses was detected in brickfield workers.},
	number = {1},
	title = {Studying the Association Between Occupational Stress and Urinary Levels of Oxidative Stress Biomarkers (8-OHdG and Biopyrrins) in Brickfield Workers},
	url = {https://journals.lww.com/joem/fulltext/2023/01000/studying_the_association_between_occupational.10.aspx},
	volume = {65},
	year = {2023},
	bdsk-url-1 = {https://journals.lww.com/joem/fulltext/2023/01000/studying_the_association_between_occupational.10.aspx}}
